LLM_MODEL=qwen2:1.5b
LLM_BASEURL=http://host.docker.internal:11434
LLM_TEMPERATURE=0.75
LLM_TOP_P=1
CHUNK_SIZE=400
CHUNK_OVERLAP=100
TOP_K=3
Q_ASK=What is Chat Model?
DB_IPADDR=host.docker.internal
DB_USER=langchain
DB_PASSWD=langchain
DB_NAME=langchain
DB_PORT=5432
COLLECTION_NAME=mydocs
DATA=sample.txt
DATA_CSV=sample.csv
EMBEDDING_MODEL=all-MiniLM-L6-v2
SYSTEM_MESSAGE=Answer the question based only on the following context